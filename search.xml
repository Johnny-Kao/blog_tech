<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【開箱】羅技二代旗艦 Logitech MX Master 2S]]></title>
    <url>%2Fblog_tech%2F%E3%80%90%E9%96%8B%E7%AE%B1%E3%80%91%E7%BE%85%E6%8A%80%E4%BA%8C%E4%BB%A3%E6%97%97%E8%89%A6%20Logitech%20MX%20Master%202S.html</url>
    <content type="text"><![CDATA[多年前服役的滑鼠在一個夜黑風高的夜晚，一動也不懂離我而去，才有了本篇的開箱 - Logitech MX Master 2 前言多年前服役的滑鼠在一個夜黑風高的夜晚，一動也不懂離我而去，才有了本篇的開箱文。由於前一款滑鼠也是羅技，使用上十分順手，因此就其中的產品線挑選出本次的主角 - Logitech MX Master 2S 滑鼠。 選擇作為一個文字工作者和金融工作者，Excel內基本全數用鍵盤搞定，Markdown可以快速的解決排版問題，對於滑鼠並沒有強烈的訴求。 如果真的要我提供購買滑鼠的建議，那麼我認為你需要考慮： 習慣 預計使用時間 實用性 習慣首先習慣這件事情很重要，科技始終始於人性，不是人去適應產品，是產品去適應人的生活。 常出現的使用場景如何？隨身攜帶滑鼠使用呢？還是一直在桌面前使用？你的手大小如何？大滑鼠適合？還是小滑鼠適合？手持習慣如何？習慣懸空抓住滑鼠？還是喜歡掌握滑鼠？有線好呢？還是無線好？ 回答上面的問題時，直觀很重要。如果思考超過10秒，代表你根本沒注意過自己的使用習慣，那麼這個時候你需要的是養成一個習慣，選擇喜歡的即可。 預計使用時間現在的消費性電子產品損壞率低，一個鍵盤、滑鼠可以使用上很長的一段時間不出問題，那麼實際上就是你會不會喜新厭舊的問題了。 大部分的滑鼠使用久了按鍵回鬆弛，沒必要勉強自己用那麼久。 鍵盤也是長時間使用下，回彈的速度很變慢或是聲音會有差別（對的，我就是那種使用機械鍵盤很在乎聲音的人）。 基本上滑鼠和鍵盤幾乎2年更換一次，當然如果你喜新厭舊另當別論。 以一個月100元來計算，一年1200元，2年2400元。2400元購買一個滑鼠我認為不過分。 實用性滑鼠功能琳瑯滿目，DPI、LED、自定義功能鍵、巨集等功能非常多，老實說你真的會用到嗎？ 如果你不會用到，而且目前也沒這個使用場景，那麼就不要把錢花在這些功能上。 對我來說：DPI不需要可以自定義，因為我不玩遊戲；LED閃閃發光不需要，也浪費點；自定義功能鍵，不是很必要，有也可以；巨集不需要，已經全部用鍵盤設定完成了。 那麼實際上，你會需要什麼功能呢？ 技術規格太專業的技術規格不寫，只寫你感覺的到的，畢竟老話一句，科技服務生活。 重量：145G（很輕） 連接方式：USB接收器 或 藍芽（接收器丟了沒關係） 支援系統：Windows、Mac、iPad、Linux（多系統，換電腦之後，不用重新買滑鼠） 單次續航時間：70天（用著舒服，不受到限制） 2個滾輪，6個按鍵 有沒有發現其實複雜的技術規格，簡單許多？ 詳細規格看這裡 特點如果你真的想要看特點，那麼我也寫幾個吧。這幾個對我來說是購買選擇時的加分項目，可有可無。 有段/無段飛梭滾輪 可以配對3組設備 電量指示燈 Flow功能 - 滑鼠可以跨系統使用，同時可以在同個區域網絡內用滑鼠複製貼上東西 自定義功能鍵 開箱開始開箱了，一起看看吧 很有隻質感的箱子，本次是在日本購買的 背面介紹了Flow的功能，可能自由的在不同電腦切換，複製貼上檔案。不過至少我是沒成功嘗試出來，估計是因為延伸螢幕的關係。 內部介紹了軟體可以設定各個按鍵的功能，但是就是沒找到下載的地方。需要自己Google一下。 全部包含滑鼠、USB接收器、micro USB充電線（嗯…不是TypeC）、保固卡 側面來一張，滾輪、上一頁/下一頁、電源狀態燈、還有一個隱藏的按鈕。 前面中規中矩，有個Logi的Logo，不知道會不會被磨掉。滾輪和設定有段無段的按鍵，無段真的很好玩，只是實際上使用機會不高。 後面突起，人體工學設計，輕鬆掌握滑鼠，手不必懸空使用。 背面的電源鍵和配對按鈕，共計可以配對3個裝置。短按切換，長按3秒進入配對模式。 小巧的接收器，Made in China，不要弄丟了，雖然也可以用藍芽配對，但接收器還是比藍芽穩定些。 設定開箱完，接下來是設定，請下載專用的軟體，請依據不同系統選擇。 Windows10版本下載 Mac OS 10.13以上版本下載 有發現左邊滑鼠的隱藏按鍵嗎？我一開始沒發現呢！可以設定不同按鍵的功能 設定滑鼠移動速度、捲動速度等選項 設定好Flow之後的畫面，設定很簡單，軟件裡面有圖形教學。但是我自己是沒成功複製檔案和切換滑鼠。 後記實際上使用滑鼠之後，剛剛的設定都不會再特別調整了，基本上你會忘記它的存在。 長時間使用起來不累，滑鼠摸起來很舒服，滾輪很靈敏，玻璃材質上移動也定位很準確。 唯一的問題就是雖然提供了Flow的功能，但是因為延伸螢幕的關係，沒有成功使用過這個功能呢。 另外開箱過程中，還必須自己去找安裝軟體很不直觀。如果有個簡單的嚮導指示說明書，也許會更好。 這個滑鼠功能特別多，如果沒有嚮導說明，就像是擁有瑞士刀，只會使用刀的功能一樣。 》Amazon購買 》日本樂天購買 累積閱讀量次]]></content>
      <categories>
        <category>開箱文</category>
      </categories>
      <tags>
        <tag>電子產品</tag>
        <tag>開箱文</tag>
        <tag>羅技</tag>
        <tag>滑鼠</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Analytics(GA)排除本机流量的 5 种方式]]></title>
    <url>%2Fblog_tech%2FGoogle%20Analytics(GA)%E6%8E%92%E9%99%A4%E6%9C%AC%E6%9C%BA%E6%B5%81%E9%87%8F%E7%9A%845%E7%A7%8D%E6%96%B9%E5%BC%8F.html</url>
    <content type="text"><![CDATA[Google Analytics(GA)其实已经内建流量过滤的功能，但是在实际使用上还是有些不方便，这边提供教学教你如何过滤掉自己的浏览数据。 为了避免数据不准确，一开始设定Google Analytics的时候，就必须将自己及公司同事的浏览数据过滤掉。 如何设定GA本身就已经内建设定工具，你可以从左下角的【设定】》【账户】》【所有筛选器】进入设定页面，根据浏览来源不同： 来自ISP网域的流量 来自IP位址的流量 子目录获得的流量 主机名称获得的流量 设定过滤非目标流量。 实际问题但是如果电脑是浮动IP，也就是说IP会随着时间而改变，那么即使设定了过滤器，基本上也是徒劳无功，该如何解决？ 解决方式解决方式有 5 个： 使用运算规则式 使用外褂 Google Analytics (分析) 不透露資訊外掛程式 IT部门屏蔽GA流量 调整GA代码 设定本地Host 第 1 种方式对于一般人有困难，但是比较有趣的是，它可以过滤到ipv6的流量，但是ipv6使用的人数不多，可能未来这个功能才会派上用场。 第 2 种方式对于个人来说是最方便的，直接安装即可，这样就会过滤掉自己的流量了。如果你没有编程能力，建议直接选这个吧。 但是如果公司是浮动流量的话，那么你只能拜托大家一个一个安装了。 第 3 种方式如果公司有IT部门，而且大家是共用WIFI的话，可以直接在WIFI路由器设定Host，屏蔽掉GA的流量。这种方式最简单，但是前提是你的IT部门必须知道他要做什么（不要怀疑，很多IT部门不知道这个东西） 第 4 种方式我觉得是最酷的方式，但是并非屏蔽所有流量，只屏蔽了网站在本地测试时候的流量。换句话说，如果网站上线后，你自己浏览的行为数据也会记录。 如果你是一个跟工程师关系很好的产品经理（虽然工程师都想要杀产品祭天？）那么极度推荐这个方式。 请他们添加代码的时候，判断是否为本地流量后，排除统计 1234567&lt;script&gt;var host &#x3D; window.location.hostname;if(host !&#x3D; &quot;localhost&quot;)&#123; &#x2F;&#x2F; your google analytic code here&#125;&lt;&#x2F;script&gt; 第 5 种方式适合工程师，直接修改本地Host文件，屏蔽GA浏览，以MAC设定为例： 123456789# 修改 Host文件jk@local:~$ vi &#x2F;etc&#x2F;hosts# 添加一下代码后，存档关闭# My filters127.0.0.1 www.google-analytics.com127.0.0.1 google-analytics.com127.0.0.1 ssl.google-analytics.com 这种方式好处是你不必安装插件即可完成。 后记介绍了那么多方式，想要简单设定的话，直接选第 2 种安装插件的方式吧！ 点击安装》Google Analytics (分析) 不透露資訊外掛程式 如何掌握自己的行为数据，一直是一个重要但是大家不关注的议题。自己的行为数据被搜集后，确实可以得到更完善的服务，何必要管理？ 细思恐极，如果你的行为被记录搜集后加以运用，当你要买什么的时候，你可以简单获得，当你不要买什么的时候，可以透过长时间的广告投放，让你逐渐改变喜好，最后决定购买。 这样的事情如果发生的话，你不觉得非常可怕吗？ 累计阅读量次]]></content>
      <categories>
        <category>SEO学习</category>
      </categories>
      <tags>
        <tag>SEO</tag>
        <tag>Google Analytics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【經驗】購買記憶卡翻車記錄]]></title>
    <url>%2Fblog_tech%2F%E3%80%90%E7%B6%93%E9%A9%97%E3%80%91%E8%B3%BC%E8%B2%B7%E8%A8%98%E6%86%B6%E5%8D%A1%E7%BF%BB%E8%BB%8A%E8%A8%98%E9%8C%84.html</url>
    <content type="text"><![CDATA[因為想要改裝iPod Classic的緣故，上網購買了一張Microsd的記憶卡.沒想到在9012年居然還有擴容卡的存在!記錄一下這次的檢測記錄，並且提供檢測方式供大家參考。 什麼是擴容卡擴容卡是指用非法手段（軟件）讓容量小的存儲卡在電腦上顯示出的容量變大（比如8G的顯成128G），這些多出來的內存是不能正常使用的，這種卡存入的文件只要超過實際的容量，多出來容量的文件不可用（如音視頻損壞，圖片打不開，手機安裝應用提示應用未安裝），數據無故丟失損壞，造成損失。 奇怪的記憶卡沒錯，就是這次的主角！一張外觀 128 GB的小米記憶卡。等等？小米記憶卡？小米也出記憶卡了？基本上就是這點，讓我一到手就測試，不測還好… 到手了，蘋果電腦Disk Utility 基本看一下，誒？ 134.21GB？這就是第二個疑點了。電腦的比較大（誤？於是乎就開始了這次的檢測~ 檢測開始本次測試使用了以下2種工具，基本上其他測試軟件都已經失效，現在的擴容卡已經能夠欺騙測試軟件了。 h2testw - Windows 本次的主角 - h2testw，由國外工程師開發非常輕量的軟件，點選 Select target，選擇自己的記憶卡後（建議先把新的卡片格式化），點擊 Write + Verify即可開始測試。 測試中會顯示寫入了多少測試數據、經過時間（預計花費時間）、目前寫入速度等資訊。基本上從這裡就可以判斷是否是擴容卡了。 從寫入速度來看，是否與外觀表示的記憶卡規格匹配，速度10MB/s基本上就是擴容卡了。一般擴容卡都會使用廉價卡片，無法有較好的表現。 不必把整張記憶卡寫滿，非常消耗時間（128GB的卡大約花費5個小時)。一般擴容卡都會使用容量小的卡片，因此可以依據標示容量的 1/2 作為測試值，如記憶卡是128GB，就可以只寫入64GB的數據作為參考。 寫入一定數據之後，選擇Abort跳出。 點擊Verify，開始校驗數據，如果運氣好，應該是什麼錯誤都沒發生。運氣不好就會出現和上圖一樣的錯誤：買到擴容卡了！ 點擊下載 》h2testw f3 - Mac OSX這是國外作者寫的測試軟件 f3，可參考此 Github專案 - F3 這邊就不展開教學了。 手動測試擴容卡將原本小容量的卡片，偽裝成大容量，那麼檔案的安全性一定有問題。因此手動也可檢測出來。 檢測步驟如下： 格式化記憶卡 - exfat, FAT32都可。 準備一個檔案3GB左右的檔案，重複存入記憶卡，如16GB的，至少可以存入5個相同的檔案。 檔案命名為file1, file2, file3…. 以此類推。 退出記憶卡，重新插入電腦。 讀取剛剛存入的檔案，如果是擴容卡，那麼一定有檔案是無法開啟或損壞的。 後記第一次遇到這樣的事情，才發現原來記憶卡這種不太獲利的產品居然出現這種謀取暴利的野路子。如果真的要購買記憶卡，建議還是從正規渠道購買，畢竟省了錢，丟了數據得不償失。 累計閱讀量次]]></content>
      <categories>
        <category>編程學習</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>測試</tag>
        <tag>電子產品</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安卓手机模拟点击-探探为例]]></title>
    <url>%2Fblog_tech%2F%E5%AE%89%E5%8D%93%E6%89%8B%E6%9C%BA%E6%A8%A1%E6%8B%9F%E7%82%B9%E5%87%BB-%E6%8E%A2%E6%8E%A2%E4%B8%BA%E4%BE%8B.html</url>
    <content type="text"><![CDATA[本篇文章介绍Adb Shell的一些实际操作，包含获取安卓手机点击坐标、开启安装的APP等，并以探探为例子，将上述技术结合。咱们开始吧！ ADB是什么？ADB的全称为Android Debug Bridge，就是起到调试桥的作用。通过ADB我们可以在Eclipse中方面通过DDMS来调试Android程序。 看不懂对吧？没关系，一句话来说就是：用来操作（调试）android设备的一套指令集。 安装ADB这么好用的工具，首先咱们先安装，此处以MAC OSX为例子 1234567# 通过 Homebrew 安装jk@local:~$ brew cask install android-platform-tools# 安装成功后，测试是否正常jk@local:~$ adb devicesList of devices attached12d6ac34 device # 有设备显示就是正常，如果没显示的话，请百度“开启安卓开发者模式”，先把调试模式打开。 获取点击坐标（16进制）123456789101112131415161718# 进入手机调试终端jk@local:~$ adb shell XXXX:&#x2F; $ # XXXX会显示你的设备名称# 开始获取手机事件，接着点击你想定位的位置，画面会持续跑出很多数据。# 想停止获取可以键盘 Crtl + C 退出XXXX:&#x2F; $ getevent -l&#x2F;dev&#x2F;input&#x2F;event2: EV_ABS ABS_MT_TRACKING_ID 000056f7&#x2F;dev&#x2F;input&#x2F;event2: EV_KEY BTN_TOOL_FINGER DOWN ## 这个是你手指按下屏幕的事件&#x2F;dev&#x2F;input&#x2F;event2: EV_ABS ABS_MT_POSITION_X 0000039c ## 这个是点击的X轴，16进位&#x2F;dev&#x2F;input&#x2F;event2: EV_ABS ABS_MT_POSITION_Y 00000263 ## 这个是点击的Y轴，16进位&#x2F;dev&#x2F;input&#x2F;event2: EV_SYN SYN_REPORT 00000000&#x2F;dev&#x2F;input&#x2F;event2: EV_ABS ABS_MT_TOUCH_MINOR 00000006&#x2F;dev&#x2F;input&#x2F;event2: EV_SYN SYN_REPORT 00000000&#x2F;dev&#x2F;input&#x2F;event2: EV_ABS ABS_MT_TRACKING_ID ffffffff&#x2F;dev&#x2F;input&#x2F;event2: EV_KEY BTN_TOOL_FINGER UP ## 这个是你手指离开屏幕的事件&#x2F;dev&#x2F;input&#x2F;event2: EV_SYN SYN_REPORT 00000000 转换点击坐标（10进制）刚刚获取的坐标为16进制，此时需要转换为10进制方便后续使用。 点击 》 在线装换工具 以刚刚获取的16进制 (x, y) = (0000039c, 00000263)为例，装换后10进制 (x, y) = (924, 611) 模拟ADB点击12# 开始模拟点击，使用转换的10进制坐标jk@local:~$ adb shell input tap 924 611 是不是成功了呢？成功的话，应该就跟你点击的动作是相同的，只是差别在于现在你是以下指令的方式点击。 点击应用 - 探探为例探探交友软件是个非常好的研究对象，首先如画面所示，用户需要点击喜欢或不喜欢来获得配对机会。这个行为就可以透过刚刚学习到的点击来试验，配合上Python的脚本后甚至可以达到自动化的目标。 需要点击喜欢和不喜欢。 分析一下具体思路： 利用Python调用终端指令，进而调用ABD 重复执行点击 控制点击的速度 可参考下列程序码： 12345678910111213141516171819# 引入模组import osimport timeimport random#点击喜欢tap1 &#x3D; &#39;adb shell input tap 725 1785&#39;#点击不喜欢tap2 &#x3D; &#39;adb shell input tap 368 1791&#39;# 重复点击150次for i in range(150): rd &#x3D; random.random() # 设置随机数 if rd &gt;&#x3D; 0.5: # 随机数大于等于0.5时，点击喜欢 os.system(tap1) # 调用ADB指令 else: # 随机数小于0.5时，点击不喜欢 os.system(tap2) # 调用ADB指令 time.sleep(0.03) # 控制点击的速度，300毫秒点击一次 具体成功如上。 后记可改良部分： 执行程序的时候，直接打开探探APP 判断图片后，选择点击喜欢/不喜欢 累计阅读量次]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Shell</tag>
        <tag>安卓</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【項目】黑群暉修改MAC地址]]></title>
    <url>%2Fblog_tech%2F%E3%80%90%E9%A0%85%E7%9B%AE%E3%80%91%E9%BB%91%E7%BE%A4%E6%9A%89%E4%BF%AE%E6%94%B9MAC%E5%9C%B0%E5%9D%80.html</url>
    <content type="text"><![CDATA[使用自組的黑群暉已經一陣子了，系統是使用網絡上常見的DS918二合一引導盤，省去了另外使用U盤的麻煩。 然而唯一美中不足的地方：無法使用常見的網絡喚醒功能（WOL），本次教學將一步一步教你如何達成目標。 事前準備 筆記本（蘋果，Windows皆可，只要能夠使用ssh功能即可） 黑群暉（安裝完成，已經可正常使用） 網絡（os. 這不是廢話？但請注意筆記本和黑群暉必須在同個局域網內） 教學開始ssh連接黑群暉筆記本打開終端機（Terminal），輸入下列指令： 1234567891011121314# 注意192.168.xxx.xxx 請修改成自己黑群暉的地址jk@local:~$ ssh admin@192.168.xxx.xxx# 連接成功admin@DS918Plus:~$# 以root執行admin@DS918Plus:~$ sudo -i# 輸入密碼後回車（不會顯示輸入的密碼）Password:# 以root登入成功root@DS918Plus:~# 掛載開機設定檔案123456789101112131415# 建立臨時掛載位置root@DS918Plus:~# mkdir &#x2F;tmp&#x2F;boot# 移動到本機設備目錄root@DS918Plus:~# cd &#x2F;dev# 掛載開機區，注意指令中的sdb4依據硬件可能為不同root@DS918Plus:&#x2F;dev# mount -t vfat sdb4 &#x2F;tmp&#x2F;boot# 掛載成功後移動到開機區root@DS918Plus:&#x2F;dev# cd &#x2F;tmp&#x2F;boot&#x2F;grub&#x2F;# 查看開機區檔案root@DS918Plus:&#x2F;tmp&#x2F;boot&#x2F;grub# lsfonts grub.cfg grubenv loader locale x86_64-efi 修改grub.cfg設定123456789101112131415161718# 修改grub.cfg設定（此處使用vi編輯器，可使用自己習慣的編輯器進行修改）root@DS918Plus:&#x2F;tmp&#x2F;boot&#x2F;grub# vi grub.cfg# 找到文件中與下列相似的內容並修改set sn&#x3D;1780PDN21xxxxset mac1&#x3D;001132xxxxxxset mac2&#x3D;001132xxxxxxset rootdev&#x3D;&#x2F;dev&#x2F;md0# 修改完成範例set sn&#x3D;1780PDN216002 # 通常不需修改set mac1&#x3D;001132e12242 # 單網卡修改此處即可，實體位置可參考主板上實體網卡set mac2&#x3D;001132xxxxxx # 雙網卡可修改此處set rootdev&#x3D;&#x2F;dev&#x2F;md0 # 維持不變# 重新啟動，完成root@DS918Plus:&#x2F;tmp&#x2F;boot&#x2F;grub# reboot 遠端開機在局域網內，可使用任意網絡喚醒工具，如手機APP、指令等，此處以python腳本為例，筆記本打開終端機（Terminal），輸入下列指令： 12345678910# 安裝套件wakeonlanjk@local:~$ pip3 install wakeonlan# 撰寫腳本jk@local:~$ python3Python 3.7.6 (default, Dec 30 2019, 19:38:28)[Clang 11.0.0 (clang-1100.0.33.16)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from wakeonlan import send_magic_packet&gt;&gt;&gt; send_magic_packet(&#39;02.11.32.2A.03.E9&#39;) # 此處MAC地址為黑群暉的地址 完成上述設定之後，即可遠端喚醒。 累計閱讀量次]]></content>
      <categories>
        <category>編程學習</category>
      </categories>
      <tags>
        <tag>NAS</tag>
        <tag>腳本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac Wifi开关脚本]]></title>
    <url>%2Fblog_tech%2FMac%20Wifi%E5%BC%80%E5%85%B3%E8%84%9A%E6%9C%AC.html</url>
    <content type="text"><![CDATA[上班族在通勤路上使用笔记本电脑的时候，一定会遇到和我相同的问题。 在 Wifi 开启的情形下，只要有新的 Wifi 可连接，就会跳出通知信息。其次就是 Wifi 耗电，使得电脑的续航力下降。 可以使用下列脚本可以快速解决问题，这个脚本将让你可以快速切换 wifi 状态，解放你的双手。 初始设定首先打开终端（terminal）切换到桌面（Desktop）建立脚本，当然你也可以选择在其他地方建立脚本。 12cd ~&#x2F;Desktoptouch wifi.sh 输入完毕后，在桌面会有一个 wifi.sh的档案，请使用文字编辑器（TextEdit）打开，输入下列指令，存档。 1234567#!&#x2F;bin&#x2F;bashif [[ &#96;networksetup -getairportpower en0&#96; &#x3D;&#x3D; *On ]]then networksetup -setairportpower en0 offelse networksetup -setairportpower en0 onfi 切换到刚刚的终端，将文件赋予执行权限，并尝试执行 12chmod +x ~&#x2F;Desktop&#x2F;wifi.sh.&#x2F;wifi.sh 执行成功之后，你会发现你的 wifi 已经关闭了。 日常使用开启终端，输入 ~/Desktop/wifi.sh 之后，就可以使用了。 如果觉得指令太长，可以使用下列方式建立 alias 解决。 123456789vi ~&#x2F;.zshrc # 光标移动到最后一行，输入 i 插入下列指令alias wifi&#x3D;&#39;~&#x2F;Desktop&#x2F;wifi.sh&#39;# 键盘按下 Esc，再输入 :wq! 存档，输入指令生效source ~&#x2F;.zshrc 之后就可以在终端输入 blog 执行指令了，这个脚本如果配上 Alfred 使用后连开启终端的步骤都可以节省了，下回专门撰写一篇教学供大家参考。 累计阅读量次]]></content>
      <categories>
        <category>编程学习</category>
        <category>Bash</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 新增分类及标签]]></title>
    <url>%2Fblog_tech%2FHexo%20%E6%96%B0%E5%A2%9E%E5%88%86%E7%B1%BB%E5%8F%8A%E6%A0%87%E7%AD%BE.html</url>
    <content type="text"><![CDATA[初次建立 Hexo 静态博客的时候，一直在寻找分类和标签是如何建立的。以前使用 Wordpress 建站的时候，这个功能很直观直接设定即可，现在则必须自行设定。 本篇将教你如何新增分类及标签，并在撰写新文章的时候使用。 创建分类首先在终端 Hexo 根目录建立分类页面 1hexo new page categories 此时会在 /source/categories/ 目录下生成 index.md 档案。 上面的这个操作是利用 Hexo 创建一个页面，该页面是以 page 的形式展现。平时我们写博客新增文章的时候，则是以 post 的形式新增文章。 将档案内容修改如下： 12345678910111213---# 这个是页面展示的时候的标题，可自行修改title: 文章分类 # 时间自动生成，不必理会date: 2019-09-20 20:33:35 # 填写 categories 即可type: categories # 如果有使用评论插件（如：Disqus），选择 false 后，该页面不会展示评论插件。 comments: false --- 上面设定完之后，基本上功能已经开通完成。那么如何在博客上显示页面呢？这边以 Next 主题为例子。 显示分类页面修改 Hexo Next主题的设定文件，路径为 theme/next/_config.yml，找到 menu 添加 categories 项目即可。 123menu: tags: &#x2F;tags&#x2F; || tags categories: &#x2F;categories&#x2F; || th 当然别忘了修改后存档，重新生成静态博客. 12hexo generatehexo deloy 完成后效果 文字撰写添加分类新增完分类后，撰写文章的时候就可以使用了 撰写文章的时候，只要加入 categories: 即可。添加的方式有 2 种，可以参考下列范例，当文章属于多个分类的时候使用方式一，单一分类的时候使用方式二。 12345678910111213---title: Hexo 新增分类及标签# 方式一categories: - 编程学习 - Hexo# 方式二 categories: 编程学习date: 2019-09-24 20:15:40--- 具体效果可参考本篇文章~ 创建标签首先在终端 Hexo 根目录建立分类页面 1hexo new page tags 此时会在 /source/tags/ 目录下生成 index.md 档案。 上面的这个操作是利用 Hexo 创建一个页面，该页面是以 page 的形式展现。平时我们写博客新增文章的时候，则是以 post 的形式新增文章。 将档案内容修改如下： 12345678910111213---# 这个是页面展示的时候的标题，可自行修改title: 文章分类 # 时间自动生成，不必理会date: 2019-09-20 20:33:35 # 填写 tags 即可type: tags # 如果有使用评论插件（如：Disqus），选择 false 后，该页面不会展示评论插件。 comments: false --- 上面设定完之后，基本上功能已经开通完成。那么如何在博客上显示页面呢？这边以 Next 主题为例子。 显示标签页面修改 Hexo Next主题的设定文件，路径为 theme/next/_config.yml，找到 menu 添加 tags 项目即可。 123menu: tags: &#x2F;tags&#x2F; || tags categories: &#x2F;categories&#x2F; || th 当然别忘了修改后存档，重新生成静态博客. 12hexo generatehexo deloy 完成后效果 文字撰写添加标签新增完标签后，撰写文章的时候就可以使用了 撰写文章的时候，只要加入 tags: 即可。添加的方式有 2 种，可以参考下列范例，当文章属于多个标签的时候使用方式一，单一标签的时候使用方式二。 12345678910111213---title: Hexo 新增分类及标签# 方式一tags: - 编程学习 - Hexo# 方式二 tags: 编程学习date: 2019-09-24 20:15:40--- 具体效果可参考本篇文章~ 有没有发现无论是分类还是标签，两种添加的方式机会相同？ 没错，这个就是 Hexo 的美妙，另外其实常见的 404 错误页面，也可以用类似的方式生成哦。下次再撰写一篇来详细解说吧。 累计阅读量次]]></content>
      <categories>
        <category>编程学习</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo建立个人主页]]></title>
    <url>%2Fblog_tech%2Fhexo-create-personal-homepage.html</url>
    <content type="text"><![CDATA[初次使用 Hexo 建立完静态博客的时候，默认的首页就是博客文章，本篇文章教你如何将首页设定成自己的静态页面。 达成效果当初始化 Hexo 静态博客部署之后，输入网址之后（你的github账号.github.io）通常你会直接进入博客主页。 但是，如果我希望优先展示个人介绍页面、个人作品集或是落地页的话，该如何处理呢？ 先进入落地页： 点击 Blog 之后才进入博客： 准备内容 静态页面 Hexo 站点设定档（_config.yml） 具体操作修改 Hexo 站点设定档找到站点设定档案，一般在 Hexo 根目录下，进行修改。 123456url: http:&#x2F;&#x2F;indeedinvest.info&#x2F;blog&#x2F; # 输入你的网址root: &#x2F;blog&#x2F; # 修改成 &#x2F;blog&#x2F;# Directorysource_dir: sourcepublic_dir: public&#x2F;blog&#x2F; # 修改成 public&#x2F;blog&#x2F; 重新生成 Hexo在终端 Hexo 根目录路径下输入下列指令，重新生成静态博客 12hexo clean # 清除旧档案hexo generate # 重新生成 确认静态页面档案一个静态页面至少包含 index.html 档案。我的静态页面包含的档案清单如下： 将所有的档案复制到 Hexo 目录下的 public 资料夹，复制成功之后如图 部署上线经过上述的操作后，你已经可以重新部署。 12hexo generate # 生成档案hexo deploy # 部署上线 是不是很简单啊？完成上述的操作之后，进入自己的页面只要输入自己的网址即可。 想要进入博客页面，输入自己的网址/blog/即可。 这样的设定能够让你轻松展示自己的作品集哦。 累计阅读量次]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas 常用基础教学]]></title>
    <url>%2Fblog_tech%2FPandas%20%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E6%95%99%E5%AD%A6.html</url>
    <content type="text"><![CDATA[Pandas 是 Python 中用于处理数据分析的一个套件，提供高效能、简易使用的资料格式（Data Frame）让使用者可以快速操作及分析资料。 一般用于金融数据处理及时间序列分析，本篇将介绍几个常见的使用方式，供读者参考。 导入 Pandas12345# 导入pandas套件import pandas as pd# 如果没安装的话，可在终端输入指令安装(Python3)pip3 install pandas 导入数据以 CSV 为例，导入数据常用的参数如下： 范例文件下载 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748df = pd.read_csv( # 文件数据路径，必填 '~/Desktop/demo.csv', # 数据分隔符，csv文件默认为逗号，选填 sep= ',', # 跳过数据文件第 1 行不读 # skiprows = 1, # 只读前 15 行，选填，默认读取全部数据 nrows = 15, # 指定列为日期格式，选填，默认全部格式为字串 parse_dates = ['OrderDate'], # 指定列设为index，选填，默认 index 为 0，1，2 index_col = ['OrderDate'], # 读取指定的列数据，选填，默认读取全部数据 usecols = ['OrderDate', 'Region', 'Rep'], # 读取数据跳过报错数据，只载入正确数据，用于脏数据较多的场景 error_bad_lines = False, # 将数据中的null识别为空值 na_values = 'NULL')# 打印结果print(df) Region Rep OrderDate 2018-01-06 East Jones 2018-01-23 Central Kivell 2018-02-09 Central Jardine 2018-02-26 Central Gill 2018-03-15 West Sorvino 2018-04-01 East Jones 2018-04-18 Central Andrews 2018-05-05 Central Jardine 2018-05-22 West Thompson 2018-06-08 East Jones 2018-06-25 Central Morgan 2018-07-12 East Howard 2018-07-29 East Parent 2018-08-15 East Jones 2018-09-01 Central Smith 数据概览12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 数据行列print(df.shape) (15, 2)# 数据列名称 print(df.columns) Index(['Region', 'Rep'], dtype='object')# 数据行名称print(df.index) DatetimeIndex(['2018-01-06', '2018-01-23', '2018-02-09', '2018-02-26', '2018-03-15', '2018-04-01', '2018-04-18', '2018-05-05', '2018-05-22', '2018-06-08', '2018-06-25', '2018-07-12', '2018-07-29', '2018-08-15', '2018-09-01'], dtype='datetime64[ns]', name='OrderDate', freq=None)# 数据列属性print(df.dtypes) Region object Rep object dtype: object# 数据前 5 行数据print(df.head(5)) Region Rep OrderDate 2018-01-06 East Jones 2018-01-23 Central Kivell 2018-02-09 Central Jardine 2018-02-26 Central Gill 2018-03-15 West Sorvino# 数据后 5 行数据print(df.tail(5)) Region Rep OrderDate 2018-06-25 Central Morgan 2018-07-12 East Howard 2018-07-29 East Parent 2018-08-15 East Jones 2018-09-01 Central Smith# 数据描述 - 用于快速了解数字类型的数据描述print(df.describe()) Region Rep count 15 15 unique 3 11 top Central Jones freq 7 4 数据读取 - 列123456789101112131415161718192021222324252627282930313233343536373839# 根据列名选取数据，类型为Seriesprint(df['Rep']) OrderDate 2018-01-06 Jones 2018-01-23 Kivell 2018-02-09 Jardine 2018-02-26 Gill 2018-03-15 Sorvino 2018-04-01 Jones 2018-04-18 Andrews 2018-05-05 Jardine 2018-05-22 Thompson 2018-06-08 Jones 2018-06-25 Morgan 2018-07-12 Howard 2018-07-29 Parent 2018-08-15 Jones 2018-09-01 Smith Name: Rep, dtype: object # 选取多列，类型为DataFrameprint(df[['Region', 'Rep']]) Region Rep OrderDate 2018-01-06 East Jones 2018-01-23 Central Kivell 2018-02-09 Central Jardine 2018-02-26 Central Gill 2018-03-15 West Sorvino 2018-04-01 East Jones 2018-04-18 Central Andrews 2018-05-05 Central Jardine 2018-05-22 West Thompson 2018-06-08 East Jones 2018-06-25 Central Morgan 2018-07-12 East Howard 2018-07-29 East Parent 2018-08-15 East Jones 2018-09-01 Central Smith 数据读取 - 行 - loc12345678910111213141516171819202122232425# 选取指定行，类型为Seriesprint(df.loc['2018-08-15']) Region East Rep Jones Name: 2018-08-15 00:00:00, dtype: object# 选取范围内多行，类型为DataFrameprint(df.loc['2018-04-18':'2018-07-12']) Region Rep OrderDate 2018-04-18 Central Andrews 2018-05-05 Central Jardine 2018-05-22 West Thompson 2018-06-08 East Jones 2018-06-25 Central Morgan 2018-07-12 East Howard# 选取范围内多行、多列，类型为DataFrameprint(df.loc['2018-04-18':'2018-06-08', 'Region':'Rep' ]) Region Rep OrderDate 2018-04-18 Central Andrews 2018-05-05 Central Jardine 2018-05-22 West Thompson 2018-06-08 East Jones 数据读取 - 列 - iloc12345678910111213141516171819202122# 选取某列，类型为Seriesprint(df.iloc[0]) Region East Rep Jones Name: 2018-01-06 00:00:00, dtype: object# 选取范围内列，类型为DataFrameprint(df.iloc[1:3]) # 包含第 1 列，不包含第 3 列，共计显示 2 列 Region Rep OrderDate 2018-01-23 Central Kivell 2018-02-09 Central Jardine # 选取范围内多行、多列，类型为DataFrameprint(df.iloc[0:5,0:1]) # 包含第 0 列，不包含第 5 列，共计显示 4 列，包含第 0 行，不包含第 1 行，共计显示 1 行 Region OrderDate 2018-01-06 East 2018-01-23 Central 2018-02-09 Central 2018-02-26 Central 2018-03-15 West 行列加减乘除123456789101112131415161718192021222324252627282930313233# 字串列加新的字符串print(df['Region'] + '_DEOM') OrderDate 2018-01-06 East_DEOM 2018-01-23 Central_DEOM 2018-02-09 Central_DEOM 2018-02-26 Central_DEOM 2018-03-15 West_DEOM Name: Region, dtype: object# 数字列可直接加减乘除df = pd.read_csv('~/Desktop/demo.csv', nrows = 15, parse_dates = ['OrderDate'], index_col = ['OrderDate']) # 重新载入范例数据print(df['Units'] * 10) OrderDate 2018-01-06 950 2018-01-23 500 2018-02-09 360 2018-02-26 270 2018-03-15 560 Name: Units, dtype: int64# 新增列名称 - Units_x10df['Units_x10'] = df['Units'] * 10df['Units_x10'] OrderDate 2018-01-06 950 2018-01-23 500 2018-02-09 360 2018-02-26 270 2018-03-15 560 2018-04-01 600 Name: Units_x10, dtype: int64 统计函数，累加1234567891011121314151617181920# 求两列的均值print(df[['Units', 'UnitCost']].mean())Units 54.533333UnitCost 15.324000dtype: float64# 求列统计数据，其他参数如 min/std/count/median/count 可自行尝试print(df['Units'].max()) 95# 累加/乘某列，cumsum()/cumprod()df['Units_CUM'] = df['Units'].cumsum()print(df[['Units', 'Units_CUM']]) Units Units_CUM OrderDate 2018-01-06 95 95 2018-01-23 50 145 2018-02-09 36 181 2018-02-26 27 208 2018-03-15 56 264 删除列，列平移1234567891011121314151617181920212223242526272829303132333435363738# Shift平移数据，原数据往下平移 1 行df['Units_Yesterday'] = df['Units'].shift(1)print(df[['Units', 'Units_Yesterday']]) Units Units_Yesterday OrderDate 2018-01-06 95 NaN 2018-01-23 50 95.0 2018-02-09 36 50.0 2018-02-26 27 36.0 2018-03-15 56 27.0 2018-04-01 60 56.0# 删除列方法 1del df['Units_Yesterday']# 删除列方法 2，inplace只是否更新原df数据df.drop(['Units_Yesterday'], axis=1, inplace=True)# 计算行差距，与上 1 行数据差距df['Gap'] = df['Units'].diff(1)print(df[['Units', 'Gap']]) Units Gap OrderDate 2018-01-06 95 NaN 2018-01-23 50 -45.0 2018-02-09 36 -14.0 2018-02-26 27 -9.0 2018-03-15 56 29.0# 计算涨跌幅df['%'] = df['Units'].pct_change(1)print(df[['Units', '%']]) Units % OrderDate 2018-01-06 95 NaN 2018-01-23 50 -0.473684 2018-02-09 36 -0.280000 2018-02-26 27 -0.250000 排名，计数123456789101112131415161718192021222324252627# 排名，ascending决定正序逆序，pct决定排名或排名比例df['Rank'] = df['Total'].rank(ascending = True, pct = False)print(df[['Total', 'Rank']]) Total Rank OrderDate 2018-01-06 189.05 6.0 2018-01-23 999.5 15.0 2018-02-09 179.64 5.0 2018-02-26 539.73 12.0 2018-03-15 167.44 3.0 2018-04-01 299.4 8.0 2018-04-18 149.25 2.0 2018-05-05 449.1 9.5 2018-05-22 63.68 14.0 2018-06-08 539.4 11.0 2018-06-25 449.1 9.5 2018-07-12 57.71 13.0 2018-07-29 1,619.19 1.0 2018-08-15 174.65 4.0 2018-09-01 250 7.0# 计数，统计列中各元素次数，类型为Seriesprint(df['Region'].value_counts()) Central 7 East 6 West 2 Name: Region, dtype: int64 筛选操作123456789101112131415161718192021222324252627282930313233343536373839404142434445# 判断列中是否符合条件，Region列中符合East的结果print(df['Region'] == 'East') OrderDate 2018-01-06 True 2018-01-23 False 2018-02-09 False 2018-02-26 False 2018-03-15 False 2018-04-01 True 2018-04-18 False Name: Region, dtype: bool # 打印出符合的结果数值print(df[df['Region'] == 'East']) Region Rep Units UnitCost Total OrderDate 2018-01-06 East Jones 95 1.99 189.05 2018-04-01 East Jones 60 4.99 299.4 2018-06-08 East Jones 60 8.99 539.4 2018-07-12 East Howard 29 1.99 57.71# 选取多个条件，并展示资料，isin(list)print(df[df['Region'].isin(['East', 'West'])]) Region Rep Units UnitCost Total OrderDate 2018-01-06 East Jones 95 1.99 189.05 2018-03-15 West Sorvino 56 2.99 167.44 2018-04-01 East Jones 60 4.99 299.4 2018-05-22 West Thompson 32 1.99 63.68 2018-06-08 East Jones 60 8.99 539.4 2018-07-12 East Howard 29 1.99 57.71 2018-07-29 East Parent 81 19.99 1,619.19 2018-08-15 East Jones 35 4.99 174.65# 选取index介于两个时间之间的所有数据print(df[(df.index &gt;= '2018-03-15') &amp; (df.index &lt;= '2018-06-25')]) Region Rep Units UnitCost Total OrderDate 2018-03-15 West Sorvino 56 2.99 167.44 2018-04-01 East Jones 60 4.99 299.4 2018-04-18 Central Andrews 75 1.99 149.25 2018-05-05 Central Jardine 90 4.99 449.1 2018-05-22 West Thompson 32 1.99 63.68 2018-06-08 East Jones 60 8.99 539.4 2018-06-25 Central Morgan 90 4.99 449.1 缺失值删除、补齐12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 找出缺失值df = pd.read_csv('~/Desktop/demo.csv', parse_dates = ['OrderDate'], index_col = ['OrderDate'], error_bad_lines = False, na_values = 'NULL') # 重新载入数据print(df.notnull()) Region Rep Item Units UnitCost Total OrderDate 2018-11-25 True True True True True True 2018-12-12 True True True False True True 2018-12-29 True True True True True True 2019-01-15 True True True True True True 2019-02-01 True True True True False True# 输出无缺失值的行print(df[df.notnull()]) Region Rep Item Units UnitCost TotalOrderDate 2018-01-06 East Jones Pencil 95.0 1.99 189.052018-01-23 Central Kivell Binder 50.0 19.99 999.52018-02-09 Central Jardine Pencil 36.0 4.99 179.642018-02-26 Central Gill Pen 27.0 19.99 539.732018-03-15 West Sorvino Pencil 56.0 2.99 167.44# 删除有空值的行，any指该行有任意空值就删除，all指所有都为空值才删除print(df.dropna(how='any')) Region Rep Item Units UnitCost TotalOrderDate 2018-01-06 East Jones Pencil 95.0 1.99 189.052018-01-23 Central Kivell Binder 50.0 19.99 999.52018-02-09 Central Jardine Pencil 36.0 4.99 179.64# 删除指定列中，有空值的行，subset用来指定可多列print(df.dropna(subset=['UnitCost'], how='any')) Region Rep Item Units UnitCost TotalOrderDate 2018-01-06 East Jones Pencil 95.0 1.99 189.052018-01-23 Central Kivell Binder 50.0 19.99 999.52018-02-09 Central Jardine Pencil 36.0 4.99 179.64# 补齐缺失值，数值来源自定义print(df.fillna(value='我是空白')) Region Rep Item Units UnitCost Total OrderDate 2018-11-08 East Parent Pen 15 19.99 299.85 2018-11-25 Central Kivell Pen Set 96 4.99 479.04 2018-12-12 Central Smith Pencil 我是空白 1.29 86.43 2018-12-29 East Parent Pen Set 74 15.99 1,183.26 2019-01-15 Central Gill Binder 46 8.99 413.54 2019-02-01 Central Smith Binder 87 我是空白 1,305.00 2019-02-18 East Jones Binder 4 4.99 19.96 2019-03-07 West Sorvino Binder 7 19.99 139.93# 补齐缺失值，数值来源为其他栏位df['Units'].fillna(value=df['UnitCost'], inplace=True)print(df[['Units', 'UnitCost']]) # 原本 2018-12-12 的 Units 为空值 Units UnitCostOrderDate 2018-11-08 15.00 19.992018-11-25 96.00 4.992018-12-12 1.29 1.292018-12-29 74.00 15.992019-01-15 46.00 8.99# 补齐缺失值，数值来源为上一个非空值,method = 'ffill'df['Units'].fillna(method='ffill', inplace=True)print(df[['Units', 'UnitCost']])# 补齐缺失值，数值来源为下一个非空值，method = 'bfill'df['Units'].fillna(method='bfill', inplace=True)print(df[['Units', 'UnitCost']])**该主题请多加练习，大部分的数据存在缺少的情形，使用频度相当高** 排序1234567891011# 重新加上 Index，通常用于多个df合并之后df.reset_index(inplace = True)# 重新加上 Index，指定 Index来源df.set_index(['OrderDate'])# 依照指定列排序，acsending决定正序/逆序，1/0print(df.sort_values(by=['OrderDate'], ascending=0))# 依照指定多列排序print(df.sort_values(by=['OrderDate', 'Units'], ascending=[1, 1])) 合并123456789101112131415161718192021222324252627282930313233343536373839404142434445# 先拆分数据df.reset_index(inplace=True)df1 = df.iloc[0:5,0:6] OrderDate Region Rep Item Units UnitCost 0 2018-01-06 East Jones Pencil 95.0 1.99 1 2018-01-23 Central Kivell Binder 50.0 19.99 2 2018-02-09 Central Jardine Pencil 36.0 4.99 3 2018-02-26 Central Gill Pen 27.0 19.99 4 2018-03-15 West Sorvino Pencil 56.0 2.99df2 = df.iloc[3:8,0:6] OrderDate Region Rep Item Units UnitCost 3 2018-02-26 Central Gill Pen 27.0 19.99 4 2018-03-15 West Sorvino Pencil 56.0 2.99 5 2018-04-01 East Jones Binder 60.0 4.99 6 2018-04-18 Central Andrews Pencil 75.0 1.99 7 2018-05-05 Central Jardine Pencil 90.0 4.99# 合并，注意df1 index 3,4 和 df2 index 3,4 两者重复，使用append的时候，不会覆盖print(df1.append(df2)) OrderDate Region Rep Item Units UnitCost 0 2018-01-06 East Jones Pencil 95.0 1.99 1 2018-01-23 Central Kivell Binder 50.0 19.99 2 2018-02-09 Central Jardine Pencil 36.0 4.99 3 2018-02-26 Central Gill Pen 27.0 19.99 4 2018-03-15 West Sorvino Pencil 56.0 2.99 3 2018-02-26 Central Gill Pen 27.0 19.99 4 2018-03-15 West Sorvino Pencil 56.0 2.99 5 2018-04-01 East Jones Binder 60.0 4.99 6 2018-04-18 Central Andrews Pencil 75.0 1.99 7 2018-05-05 Central Jardine Pencil 90.0 4.99# 合并，ignore_index重编indexprint(df1.append(df2, ignore_index = True)) OrderDate Region Rep Item Units UnitCost 0 2018-01-06 East Jones Pencil 95.0 1.99 1 2018-01-23 Central Kivell Binder 50.0 19.99 2 2018-02-09 Central Jardine Pencil 36.0 4.99 3 2018-02-26 Central Gill Pen 27.0 19.99 4 2018-03-15 West Sorvino Pencil 56.0 2.99 5 2018-02-26 Central Gill Pen 27.0 19.99 6 2018-03-15 West Sorvino Pencil 56.0 2.99 7 2018-04-01 East Jones Binder 60.0 4.99 8 2018-04-18 Central Andrews Pencil 75.0 1.99 9 2018-05-05 Central Jardine Pencil 90.0 4.99 去重12345678910111213141516# 建立df3df3 = df1.append(df2, ignore_index = True)# 去重处理df3.drop_duplicates( # 指定根据那些字段为标准，去重；默认全部 subset=['Region', 'Rep', 'Item', 'Units'], # 重复数据如何处理，保留第一条数据，后一条数据，或是一个都不留；first/last/False keep = 'first', # 是否取代原数据 inplace = False )## 改columns名称 字符串处理1234# 字串改为大写print(df['Region'].str.upper())**传统字串处理的方式基本上都可以使用，如len, lower, contains, replace, split等 时间处理12345678910111213141516171819202122232425262728293031323334# 重新载入资料df = pd.read_csv('~/Desktop/demo.csv', sep = ',')# 原数据Orderdate为object形态print(df.dtypes) OrderDate object Region object Rep object Item object Units float64 UnitCost float64 Total object dtype: object# 改为时间变量df['OrderDate'] = pd.to_datetime(df['OrderDate'])# 新数据Orderdate为datetime64[ns] OrderDate datetime64[ns] Region object Rep object Item object Units float64 UnitCost float64 Total object dtype: object# 输出时间的年/月/日/时/分/秒/几周/几天/周天/英文周几，year/month/day/hour/minute/second/week/dayofyear/dayofweek/weekday_namedf['OrderDate'].dt.year**此处很多参数可使用，可参考官方文件**# 增加时间差，Timedelta 增加 1 天print(df['OrderDate'] + pd.Timedelta(days=1)) Rolling、Expanding操作123456789101112131415161718192021# 计算包含该数据，前推 3 个数据的均值，可配合 max, min, std等使用df['R3'] = df['Units'].rolling(3).mean()print(df) OrderDate Region Item Units UnitCost Total R3 0 2018-01-06 East Pencil 95.0 1.99 189.05 NaN 1 2018-01-23 Central Binder 50.0 19.99 999.5 NaN 2 2018-02-09 Central Pencil 36.0 4.99 179.64 60.333333 3 2018-02-26 Central Pen 27.0 19.99 539.73 37.666667 4 2018-03-15 West Pencil 56.0 2.99 167.44 39.666667 5 2018-04-01 East Binder 60.0 4.99 299.4 47.666667# 计算从数据开始到该数据的均值df['Till_Now'] = df['Units'].expanding().mean()print(df) OrderDate Region Item Units UnitCost Total Till_Now 0 2018-01-06 East Pencil 95.0 1.99 189.05 95.000000 1 2018-01-23 Central Binder 50.0 19.99 999.5 72.500000 2 2018-02-09 Central Pencil 36.0 4.99 179.64 60.333333 3 2018-02-26 Central Pen 27.0 19.99 539.73 52.000000 4 2018-03-15 West Pencil 56.0 2.99 167.44 52.800000 5 2018-04-01 East Binder 60.0 4.99 299.4 54.000000 其他12# 修改column名称，字典数据&#123;'原名称':'新名称'&#125;df.rename(columns=&#123;'Region': '区域'&#125;) 输出存档12# 输出成csv档案df.to_csv('output.csv', encoding='gbk', index=False) 累计阅读量次]]></content>
      <categories>
        <category>编程学习</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>资料处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【技術】自動備份 - Time Machine Rsync]]></title>
    <url>%2Fblog_tech%2F%E3%80%90%E6%8A%80%E8%A1%93%E3%80%91%E8%87%AA%E5%8B%95%E5%82%99%E4%BB%BD%20-%20Time%20Machine%20Rsync.html</url>
    <content type="text"><![CDATA[撰寫這個腳本前，一直認為自己的檔案不重要，平時沒有養成備份的習慣。直到電腦的硬盤毀損之後，才發現原來平時日常產生出的點滴，還是值得備份的。 简介本腳本可達成MAC OS系統電腦，定期將本地指定資料夾，備份到遠端服務器。 備份方式採用增量備份，使用了Rsync-time-backup 腳本，可以依照時間點回滾回复，與Timemachine達成同樣的備份效果。 系統環境 MAC OS 10.11 以上 Python3.7.0 以上 遠端服務器與本機需先配置免密登錄SSH 設定方式 複製專案到本地git clone https://github.com/Johnny-Kao/Time-Machine-Mac-Backup.git 複製備份腳本Rsync_tmbackup.sh到本地cp Time-Machine-Mac-Backup/rsync_tmbackup.sh /usr/local/bin/rsync_tmbackup.sh 賦予執行權限chmod +x /usr/local/bin/rsync_tmbackup.sh 設定遠端與服務端免密登錄Linux SSH免密登錄 設定排除備份清單 - 參考項目中檔案Exclude.txt格式 設定基本參數 - 修改Backup.py 123456789101112131415161718192021# Log路徑&#x2F;名稱log_path &#x3D; &#39;YOUR PATH HERE&#39;# WIFI白名單 - 判定是否為指定局域網wifi_list &#x3D; [&#39;YOUR WIFI SSID HERE&#39;, &#39;YOUR WIFI SSID HERE&#39;, &#39;YOUR WIFI SSID HERE&#39;]# 備份主程序路徑&#x2F;不備份路徑（排除清單）exe_path &#x3D; &#39;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;rsync_tmbackup.sh&#39;exclude_list_path &#x3D; &#39;YOUR EXCLUDE TXT FILE HERE&#39;# 遠端服務器ip&#x2F;遠端服務器使用者（需要設定遠端免密登錄）only_sync_in_local &#x3D; &quot;F&quot; # 是否強制局域網更新？ T&#x2F;Fremote_ip_internal &#x3D; &#39;INTERNAL IP - EX. 192.168.0.1&#39; # 局域網IPremote_ip_external &#x3D; &#39;EXTERNAL IP - EX. 143.10.10.10&#39; # 公網IPremote_user &#x3D; &#39;YOUR NAS REMOTE SERVER NAME&#39;# 備份路徑[本地，遠端]backup_path &#x3D; [ [&#39;LOCAL SOURCE, EX. ~&#x2F;Downloads&#39;,&#39;REMOTE DEST, EX. &#x2F;volume3&#x2F;NAS&#x2F;MacAirBackup&#x2F;Downloads&#x2F;&#39;], [&#39;LOCAL SOURCE, EX. ~&#x2F;Downloads&#39;,&#39;REMOTE DEST, EX. &#x2F;volume3&#x2F;NAS&#x2F;MacAirBackup&#x2F;Downloads&#x2F;&#39;]] 首次執行 python3 Backup.py 首次運行請先參考log檔案 123# 你會發現log中含有下列的指令，如果你有10個備份路徑，log中就會有10個指令。請依照您的設定，依序在本機執行。ssh -p 22 遠端服務器賬戶@遠端服務器IP &#39;mkdir -p -- &quot;&#x2F;volume3&#x2F;NAS&#x2F;MacAirBackup&#x2F;Downloads&quot; ; touch &quot;&#x2F;volume3&#x2F;NAS&#x2F;MacAirBackup&#x2F;Downloads&#x2F;backup.marker&quot;&#39; 添加定期備份功能 crontab -e 待開發清單 復原功能 - 定期、手動 累計閱讀量次]]></content>
      <categories>
        <category>技術分享</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Backup</tag>
        <tag>MAC</tag>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[關於部落格]]></title>
    <url>%2Fblog_tech%2F%E9%97%9C%E6%96%BC%E9%83%A8%E8%90%BD%E6%A0%BC.html</url>
    <content type="text"><![CDATA[部落格內容包含日常隨筆、日文學習、程序設計及旅遊遊記。透過文章分享經驗，希望讓你少走彎路，熱享生活。 充滿熱情的金融科技從業人員 = 70% 金融從業人員 + 10% 日文學習者 + 10% 投資交易員 + 5% 數據分析師 + 5% 工程師。 累计阅读量次]]></content>
  </entry>
</search>
